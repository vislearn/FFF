{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d0728-44ef-4746-88b0-c5ad5e1ae1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import fff\n",
    "import fff.evaluate.bg as bg_eval\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from IPython.display import display\n",
    "from tqdm.auto import tqdm, trange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae14496-276b-4c5f-bbed-b919ae27df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {\n",
    "    \"dw4\": [\n",
    "        # Insert the lightning_log directories of your runs here:\n",
    "        \"v24-dw4 beta=10 bs=256 lc=20 lr=0.001 gc=1\",\n",
    "        \"v28-dw4 beta=10 bs=256 lc=20 lr=0.001 gc=1\",\n",
    "        \"v29-dw4 beta=10 bs=256 lc=20 lr=0.001 gc=1\",\n",
    "    ],\n",
    "    \"lj13\": [\n",
    "        # Insert the lightning_log directories of your runs here:\n",
    "        \"v12-lj13 beta=200 bs=256 lc=8 lr=0.001 gc=1\",\n",
    "        \"v31-lj13 beta=200 bs=256 lc=8 lr=0.001 gc=1\",\n",
    "        \"v38-lj13 beta=200 bs=256 lc=8 lr=0.001 gc=1\",\n",
    "        \"v39-lj13 beta=200 bs=256 lc=8 lr=0.001 gc=1\",\n",
    "    ],\n",
    "    \"lj55\": [\n",
    "        # Insert the lightning_log directories of your runs here:\n",
    "        \"v34-lj55 beta=500 bs=56 lc=8 lr=0.001 gc=0.1\",\n",
    "        \"v47-lj55 beta=500 bs=56 lc=8 lr=0.001 gc=0.1\",\n",
    "        \"v59-lj55 beta=500 bs=56 lc=8 lr=0.001 gc=0.1\",\n",
    "    ],\n",
    "}\n",
    "# With how many samples to compute the Boltzmann generator metrics\n",
    "n_samples = {\n",
    "    \"dw4\": 10000,\n",
    "    \"lj13\": 1000,\n",
    "    \"lj55\": 100\n",
    "}\n",
    "# Change the batch size to fit your GPU memory\n",
    "batch_size = {\n",
    "    \"dw4\": 1000,\n",
    "    \"lj13\": 300,\n",
    "    \"lj55\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b02ba0-6d6b-44fa-a870-cfe56efa2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db795f3d-8082-4b29-afc8-b15e0d63ec75",
   "metadata": {},
   "source": [
    "model.train_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f6ba54a-dbaf-48cb-a26a-ec1fd03c834f",
   "metadata": {},
   "source": [
    "model.get_latent(torch.device(\"cuda\")).__dict__[\"nodes_dist\"].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee6b8b-ee70-49ea-b782-800ce23df94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "device = \"cuda\"\n",
    "time_repetitions = 10\n",
    "reload(bg_eval)\n",
    "\n",
    "for dataset, run_names in runs.items():\n",
    "    ckpt_files = []\n",
    "    for base_path in sorted(Path(\"lightning_logs_selected\").absolute().iterdir()):\n",
    "        if not any(k in base_path.name for k in run_names):\n",
    "            continue\n",
    "        ckpt_dir = base_path / \"checkpoints\"\n",
    "        if not ckpt_dir.exists():\n",
    "            continue\n",
    "        ckpt_file = ckpt_dir / \"last.ckpt\"\n",
    "        if not ckpt_file.exists():  # or ckpt_file.stat().st_mtime > time() - 5 * 60:\n",
    "            ckpt_file = max(ckpt_dir.iterdir(), key=lambda p: p.name)\n",
    "        hparams_file = base_path / \"hparams.yaml\"\n",
    "        if not hparams_file.is_file():\n",
    "            continue\n",
    "        with hparams_file.open() as f:\n",
    "            hparams = yaml.safe_load(f)\n",
    "        if hparams[\"data_set\"][\"name\"] != dataset:\n",
    "            continue\n",
    "        ckpt_files.append(ckpt_file)\n",
    "\n",
    "    assert len(run_names) == len(ckpt_files)\n",
    "\n",
    "    models = []\n",
    "    data = []\n",
    "    for ckpt_file in tqdm(ckpt_files):\n",
    "        ckpt = torch.load(ckpt_file)\n",
    "        ckpt[\"hyper_parameters\"][\"data_set\"][\"root\"] = \"../data\"\n",
    "        model = fff.FreeFormFlow(ckpt[\"hyper_parameters\"])\n",
    "        model.load_state_dict(ckpt[\"state_dict\"])\n",
    "        model.to(device)\n",
    "\n",
    "        model.hparams.batch_size = batch_size[dataset]\n",
    "\n",
    "        # This creates a cache file\n",
    "        dim, n_dimensions, n_particles, target = bg_eval._tgt_info(model)\n",
    "        bg, bg_samples = bg_eval.sample_boltzmann(model, ckpt_file, n_samples[dataset])\n",
    "        nll = bg_eval.nll(model, ckpt_file, bg)\n",
    "\n",
    "        # Raw sampling time\n",
    "        raw_sampling_time = float(\"inf\")\n",
    "        latent = model.get_latent(torch.device(\"cuda\"))\n",
    "        with torch.no_grad():\n",
    "            for bs in tqdm(10 ** np.arange(5)):\n",
    "                start = time()\n",
    "                try:\n",
    "                    for _ in trange(time_repetitions):\n",
    "                        z = latent.sample((int(bs),))[0].reshape(bs, n_particles, n_dimensions)\n",
    "                        conditioned = model.apply_conditions([z])\n",
    "                        x = model.decode(conditioned.x0, conditioned.condition)\n",
    "                except RuntimeError as e:\n",
    "                    print(e)\n",
    "                    break\n",
    "                raw_sampling_time = min(\n",
    "                    (time() - start) / bs / time_repetitions,\n",
    "                    raw_sampling_time\n",
    "                )\n",
    "        data.append({\n",
    "            \"run\": ckpt_file.parents[1].name,\n",
    "            \"model\": model,\n",
    "            \"ckpt_file\": ckpt_file,\n",
    "            \"raw_sample_time\": raw_sampling_time,\n",
    "            # \"log_prob_sample_time\": bg_samples[\"times_np\"].mean(),\n",
    "            \"nll\": nll\n",
    "        })\n",
    "\n",
    "    dfs[dataset] = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e557f68-2683-4388-a8f0-c294007ffdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, df in dfs.items():\n",
    "    print(dataset)\n",
    "    display(df)\n",
    "    for col in df:\n",
    "        if \"time\" in col:\n",
    "            df[col] *= 1000\n",
    "    df = df.set_index(\"run\").describe()\n",
    "    for col in df:\n",
    "        print(f\"{col}: {df[col]['mean']:.3f} Â± {df[col]['std']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337ed89-8cd2-40c1-a7bd-5bc2873eb0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
